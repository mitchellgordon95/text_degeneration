# Model configurations

models:
  # GPT-2 models (HuggingFace)
  gpt2:
    type: huggingface
    model_id: gpt2
    device: auto

  gpt2-medium:
    type: huggingface
    model_id: gpt2-medium
    device: auto

  gpt2-large:
    type: huggingface
    model_id: gpt2-large
    device: auto
    load_in_8bit: false  # Set to true if low on VRAM

  gpt2-xl:
    type: huggingface
    model_id: gpt2-xl
    device: auto
    load_in_8bit: false

  # OpenAI models
  gpt-3.5-turbo-instruct:
    type: openai
    model_id: gpt-3.5-turbo-instruct
    cost_per_1k: 0.002

  gpt-4:
    type: openai
    model_id: gpt-4
    cost_per_1k: 0.04

  gpt-4-turbo:
    type: openai
    model_id: gpt-4-turbo-preview
    cost_per_1k: 0.02

  # Anthropic models
  claude-3-5-sonnet-20241022:
    type: anthropic
    model_id: claude-3-5-sonnet-20241022
    cost_per_1k: 0.003

  claude-3-opus:
    type: anthropic
    model_id: claude-3-opus-20240229
    cost_per_1k: 0.015

  claude-3-haiku:
    type: anthropic
    model_id: claude-3-haiku-20240307
    cost_per_1k: 0.00025

  # Llama models (HuggingFace)
  llama3-8b:
    type: huggingface
    model_id: meta-llama/Meta-Llama-3-8B
    device: auto
    load_in_8bit: true  # Recommended for consumer GPUs

  llama3-70b:
    type: huggingface
    model_id: meta-llama/Meta-Llama-3-70B
    device: auto
    load_in_8bit: true  # Required for most GPUs

# Cost tracking settings
cost_tracking:
  track_costs: true
  warn_at_cost: 10.0  # Warn when total cost exceeds this
  stop_at_cost: 50.0  # Stop experiments when total cost exceeds this